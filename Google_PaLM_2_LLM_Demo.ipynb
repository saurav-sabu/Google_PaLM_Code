{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install the Google Generative AI package"
      ],
      "metadata": {
        "id": "HRzcLT0h2uWm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tubsHJJWxqgB"
      },
      "outputs": [],
      "source": [
        "! pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries"
      ],
      "metadata": {
        "id": "KrE9U29r2x0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "VQZc26CCzHfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get API key from user data\n"
      ],
      "metadata": {
        "id": "m0jhh5fE2972"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('PALM_API_KEY')"
      ],
      "metadata": {
        "id": "oMblmYsizjBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the API with the obtained key\n"
      ],
      "metadata": {
        "id": "-6JzP9C83Che"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palm.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "nMxjTXbDzmFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List available models"
      ],
      "metadata": {
        "id": "tBDJvzRD3Ew9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in palm.list_models():\n",
        "  print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YkmYZ26ozrOd",
        "outputId": "54e6b542-f70f-4da9-c383-059f7a47937c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/chat-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 Chat (Legacy)',\n",
            "      description='A legacy text-only model optimized for chat conversations',\n",
            "      input_token_limit=4096,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
            "      temperature=0.25,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/text-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 (Legacy)',\n",
            "      description='A legacy model that understands text and generates text as an output',\n",
            "      input_token_limit=8196,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
            "      temperature=0.7,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/embedding-gecko-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding Gecko',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=1024,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
            "                   'model that supports tuning.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Latest',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
            "                   'model.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-vision-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-1.5-flash-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro',\n",
            "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-pro-vision',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/embedding-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding 001',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/text-embedding-004',\n",
            "      base_model_id='',\n",
            "      version='004',\n",
            "      display_name='Text Embedding 004',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/aqa',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Model that performs Attributed Question Answering.',\n",
            "      description=('Model trained to return answers to questions that are grounded in provided '\n",
            "                   'sources, along with estimating answerable probability.'),\n",
            "      input_token_limit=7168,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateAnswer'],\n",
            "      temperature=0.2,\n",
            "      top_p=1.0,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List available models for text generation"
      ],
      "metadata": {
        "id": "7EhGZENc3KuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "for model in palm.list_models():\n",
        "  if \"generateText\" in model.supported_generation_methods:\n",
        "    models.append(model)"
      ],
      "metadata": {
        "id": "iLSjai6nzwF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose the first model that supports text generation"
      ],
      "metadata": {
        "id": "FYopGKuD3Srd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models[0].name\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2rOxH_IC0zp-",
        "outputId": "1b09440c-5b40-4edd-8608-0c743a815389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'models/text-bison-001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "GTJGZYJp3ZYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for generating a summary\n",
        "prompt = \"\"\"\n",
        "\n",
        "Provide summary of the below data:\n",
        "\n",
        "Narendra Damodardas Modi (Gujarati: [ˈnəɾendɾə dɑmodəɾˈdɑs ˈmodiː] ⓘ; born 17 September 1950)[b] is an Indian politician who has served as the 14th prime minister of India since May 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the Member of Parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister from outside the Indian National Congress.\n",
        "\n",
        "Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education. He was introduced to the RSS at the age of eight. His account of helping his father sell tea at the Vadnagar railway station has not been reliably corroborated. At age 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so. Modi became a full-time worker for the RSS in Gujarat in 1971. The RSS assigned him to the BJP in 1985 and he held several positions within the party hierarchy until 2001, rising to the rank of general secretary.[c]\n",
        "\n",
        "In 2001, Modi was appointed Chief Minister of Gujarat and elected to the legislative assembly soon after. His administration is considered complicit in the 2002 Gujarat riots,[d] and has been criticised for its management of the crisis. A little over 1,000 people were killed, according to official records, three-quarters of whom were Muslim; independent sources estimated 2,000 deaths, mostly Muslim.[11] A Special Investigation Team appointed by the Supreme Court of India in 2012 found no evidence to initiate prosecution proceedings against him.[e] While his policies as chief minister, which were credited for encouraging economic growth, were praised, Modi's administration was criticised for failing to significantly improve health, poverty and education indices in the state.[f] In the 2014 Indian general election, Modi led the BJP to a parliamentary majority, the first for a party since 1984. His administration increased direct foreign investment, and it reduced spending on healthcare, education, and social-welfare programmes. Modi began a high-profile sanitation campaign, controversially initiated the 2016 demonetisation of high-denomination banknotes and introduced the Goods and Services Tax, and weakened or abolished environmental and labour laws.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AwJFTtC00FCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text based on the provided prompt\n",
        "completion = palm.generate_text(\n",
        "    model = model,\n",
        "    prompt = prompt,\n",
        "    temperature = 0.3,\n",
        "    max_output_tokens=800\n",
        ")\n",
        "\n",
        "# Print the generated summary\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "JazJKOO60pmv",
        "outputId": "f8d08f78-305d-47ef-9651-a1cfec97b8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Narendra Modi is an Indian politician who has served as the 14th prime minister of India since May 2014. He was the chief minister of Gujarat from 2001 to 2014 and is the Member of Parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister from outside the Indian National Congress.\n",
            "\n",
            "Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education. He was introduced to the RSS at the age of eight. His account of helping his father sell tea at the Vadnagar railway station has not been reliably corroborated. At age 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so. Modi became a full-time worker for the RSS in Gujarat in 1971. The RSS assigned him to the BJP in 1985 and he held several positions within the party hierarchy until 2001, rising to the rank of general secretary.\n",
            "\n",
            "In 2001, Modi was appointed Chief Minister of Gujarat and elected to the legislative assembly soon after. His administration is considered complicit in the 2002 Gujarat riots, and has been criticised for its management of the crisis. While his policies as chief minister, which were credited for encouraging economic growth, were praised, Modi's administration was criticised for failing to significantly improve health, poverty and education indices in the state.\n",
            "\n",
            "In the 2014 Indian general election, Modi led the BJP to a parliamentary majority, the first for a party since 1984. His administration increased direct foreign investment, and it reduced spending on healthcare, education, and social-welfare programmes. Modi began a high-profile sanitation campaign, controversially initiated the 2016 demonetisation of high-denomination banknotes and introduced the Goods and Services Tax, and weakened or abolished environmental and labour laws.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding"
      ],
      "metadata": {
        "id": "amTMCNo03m7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for generating Python code to add two numbers\n",
        "prompt = \"\"\"\n",
        "Write a code to add two numbers in python\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Zf7F6i-01aJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Python code based on the provided prompt\n",
        "completion = palm.generate_text(\n",
        "    model = model,\n",
        "    prompt = prompt,\n",
        "    temperature = 0.3,\n",
        "    max_output_tokens=800\n",
        ")\n",
        "\n",
        "# Print the generated Python code\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "8zNnDJ241pjc",
        "outputId": "61d5a42e-082d-4dc2-8562-f195962568a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def add(a, b):\n",
            "  \"\"\"Adds two numbers and returns the result.\"\"\"\n",
            "  return a + b\n",
            "\n",
            "print(add(10, 20))  # Prints 30\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "mZOr8SgT3wfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for generating a translation\n",
        "prompt = \"\"\"\n",
        "My name is saurav. Translate to hindi\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M8HNVh341sVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text based on the provided prompt\n",
        "completion = palm.generate_text(\n",
        "    model = model,\n",
        "    prompt = prompt,\n",
        "    temperature = 0.3,\n",
        "    max_output_tokens=800\n",
        ")\n",
        "\n",
        "# Print the generated translation\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8ElUXu8y32F2",
        "outputId": "169c0572-1a24-4b65-d873-e123e045df99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "मेरा नाम सौरव है।\n"
          ]
        }
      ]
    }
  ]
}